{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from utils.readers import read_ts\n",
    "from utils.utils import save_results\n",
    "\n",
    "from models import common_utils\n",
    "from models.metrics import print_metrics_binary\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "def read_and_extract_features(reader, period, features):\n",
    "    ret = common_utils.read_chunk(reader, reader.get_number_of_examples())\n",
    "    X = common_utils.extract_features_from_rawdata(ret['X'], ret['header'], period, features)\n",
    "    return (X, ret['y'], ret['name'])\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.period='all' \n",
    "#  which period extract features from\n",
    "# ['first4days', 'first8days', 'last12hours', 'first25percent', 'first50percent', 'all']\n",
    "\n",
    "#args.features='mean' \n",
    "args.features='all' \n",
    "# 'specifies which summary statistics to extract as features '\n",
    "# [min, max, np.mean, np.std, skew, len, all]\n",
    "\n",
    "args.period2=48.0 \n",
    "# which post ICU discharge timeframe to use for prediction\n",
    "\n",
    "args.l2=True\n",
    "args.C=0.001 # optimized if all-all-48-l2\n",
    "\n",
    "args.output_dir='models/output'\n",
    "args.data='s3://aws-glue-scripts-271538242229-us-west-2/data/in-hospital-mortality/'\n",
    "\n",
    "print(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_reader = read_ts(dataset_dir='data/in-hospital-mortality/train/',\n",
    "                                         listfile='data/in-hospital-mortality/train_listfile.csv',\n",
    "                                         period_length=args.period2)\n",
    "val_reader = read_ts(dataset_dir='data/in-hospital-mortality/train/',\n",
    "                                       listfile='data/in-hospital-mortality/val_listfile.csv',\n",
    "                                       period_length=args.period2) # by default 20% of train dataset is left for validation data\n",
    "\n",
    "\n",
    "test_reader = read_ts(dataset_dir='data/in-hospital-mortality/test/',\n",
    "                                        listfile='data/in-hospital-mortality/test_listfile.csv',\n",
    "                                        period_length=args.period2)\n",
    "\n",
    "# uncomment following if run locally\n",
    "# args.data='C:/Users/sy/Downloads/cse 6250/project/mimic3/data/in-hospital-mortality'\n",
    "# train_reader = read_ts(dataset_dir=os.path.join(args.data, 'train'),\n",
    "#                                      listfile=os.path.join(args.data, 'train_listfile.csv'),\n",
    "#                                      period_length=48.0)\n",
    "\n",
    "# val_reader = read_ts(dataset_dir=os.path.join(args.data, 'train'),\n",
    "#                                    listfile=os.path.join(args.data, 'val_listfile.csv'),\n",
    "#                                    period_length=48.0)\n",
    "\n",
    "# test_reader = read_ts(dataset_dir=os.path.join(args.data, 'test'),\n",
    "#                                         listfile=os.path.join(args.data, 'test_listfile.csv'),\n",
    "#                                         period_length=48.0)\n",
    " \n",
    "#train_reader.read_example(0)\n",
    "\n",
    "print('Reading data and extracting features ...')\n",
    "(train_X, train_y, train_names) = read_and_extract_features(train_reader, args.period, args.features)\n",
    "(val_X, val_y, val_names) = read_and_extract_features(val_reader, args.period, args.features)\n",
    "(test_X, test_y, test_names) = read_and_extract_features(test_reader, args.period, args.features)\n",
    "print('  train data shape = {}'.format(train_X.shape))\n",
    "print('  validation data shape = {}'.format(val_X.shape))\n",
    "print('  test data shape = {}'.format(test_X.shape))\n",
    "\n",
    "print('Imputing missing values ...')\n",
    "imputer = Imputer(missing_values=np.nan, strategy='mean', axis=0, verbose=0, copy=True)\n",
    "imputer.fit(train_X)\n",
    "train_X = np.array(imputer.transform(train_X), dtype=np.float32)\n",
    "val_X = np.array(imputer.transform(val_X), dtype=np.float32)\n",
    "test_X = np.array(imputer.transform(test_X), dtype=np.float32)\n",
    "\n",
    "print('Normalizing the data to have zero mean and unit variance ...')\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "train_X = scaler.transform(train_X)\n",
    "val_X = scaler.transform(val_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "penalty = ('l2' if args.l2 else 'l1')\n",
    "file_name = '{}.{}.{}.C{}'.format(args.period, args.features, penalty, args.C)\n",
    "\n",
    "logreg = LogisticRegression(penalty=penalty, C=args.C, random_state=42)\n",
    "logreg.fit(train_X, train_y)\n",
    "\n",
    "result_dir = os.path.join(args.output_dir, 'logistic')\n",
    "common_utils.create_directory(result_dir)\n",
    "\n",
    "with open(os.path.join(result_dir, 'train_{}.json'.format(file_name)), 'w') as res_file:\n",
    "    ret = print_metrics_binary(train_y, logreg.predict_proba(train_X))\n",
    "    ret = {k : float(v) for k, v in ret.items()}\n",
    "    json.dump(ret, res_file)\n",
    "\n",
    "with open(os.path.join(result_dir, 'val_{}.json'.format(file_name)), 'w') as res_file:\n",
    "    ret = print_metrics_binary(val_y, logreg.predict_proba(val_X))\n",
    "    ret = {k: float(v) for k, v in ret.items()}\n",
    "    json.dump(ret, res_file)\n",
    "\n",
    "prediction = logreg.predict_proba(test_X)[:, 1]\n",
    "\n",
    "with open(os.path.join(result_dir, 'test_{}.json'.format(file_name)), 'w') as res_file:\n",
    "    ret = print_metrics_binary(test_y, prediction)\n",
    "    ret = {k: float(v) for k, v in ret.items()}\n",
    "    json.dump(ret, res_file)\n",
    "\n",
    "save_results(test_names, prediction, test_y,\n",
    "             os.path.join(args.output_dir, 'logistic/test_predictions', file_name + '.csv'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
