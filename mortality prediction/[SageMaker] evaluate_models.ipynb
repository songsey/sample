{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. resample the test results by bootstrapping\n",
    "'''\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from models.metrics import print_metrics_binary\n",
    "\n",
    "import sklearn.utils as sk_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--save_file', type=str, default='results.json')\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.n_iters=10000 # number of bootstrapped samples from the test data\n",
    "\n",
    "# illustrative prediction data \n",
    "args.prediction=\"test_predictions/k_gru.n16.d0.3.dep2.bs8.ts1.0.epoch10.test0.2858196917729375.state.csv\"\n",
    "\n",
    "pred_df = pd.read_csv(args.prediction, index_col=False)\n",
    "args.test_listfile='s3://aws-glue-scripts-271538242229-us-west-2/data/in-hospital-mortality/test/listfile.csv' # this includes targets\n",
    "\n",
    "test_df = pd.read_csv(args.test_listfile, index_col=False)\n",
    "\n",
    "df = test_df.merge(pred_df, left_on='stay', right_on='stay', how='left', suffixes=['_l', '_r'])\n",
    "assert (df['prediction'].isnull().sum() == 0)\n",
    "assert (df['y_true_l'].equals(df['y_true_r']))\n",
    "\n",
    "metrics = [('AUC of ROC', 'auroc'),\n",
    "           ('AUC of PRC', 'auprc'),\n",
    "           ('min(+P, Se)', 'minpse')]\n",
    "\n",
    "data = np.zeros((df.shape[0], 2))\n",
    "data[:, 0] = np.array(df['prediction'])\n",
    "data[:, 1] = np.array(df['y_true_l'])\n",
    "\n",
    "results = dict()\n",
    "results['n_iters'] = args.n_iters\n",
    "ret = print_metrics_binary(data[:, 1], data[:, 0], verbose=0)\n",
    "for (m, k) in metrics:\n",
    "    results[m] = dict()\n",
    "    results[m]['value'] = ret[k]\n",
    "    results[m]['runs'] = []\n",
    "\n",
    "for i in range(args.n_iters):\n",
    "    cur_data = sk_utils.resample(data, n_samples=len(data))\n",
    "    ret = print_metrics_binary(cur_data[:, 1], cur_data[:, 0], verbose=0)\n",
    "    for (m, k) in metrics:\n",
    "        results[m]['runs'].append(ret[k])\n",
    "\n",
    "for (m, k) in metrics:\n",
    "    runs = results[m]['runs']\n",
    "    results[m]['mean'] = np.mean(runs)\n",
    "    results[m]['median'] = np.median(runs)\n",
    "    results[m]['std'] = np.std(runs)\n",
    "    results[m]['2.5% percentile'] = np.percentile(runs, 2.5)\n",
    "    results[m]['97.5% percentile'] = np.percentile(runs, 97.5)\n",
    "    results[m]['25% percentile'] = np.percentile(runs, 25)\n",
    "    results[m]['75% percentile'] = np.percentile(runs, 75)\n",
    "    \n",
    "print(\"Saving the results in {} ...\".format(args.save_file))\n",
    "with open(args.save_file, 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read resampled data\n",
    "\n",
    "file6='ihm_results.json'\n",
    "# file='ihm_results_lstm.json'\n",
    "# file2='ihm_results_lr.json'\n",
    "# file3='ihm_results_lr_24.json'\n",
    "# file4='ihm_results_lstm_bi_tr_16.json'\n",
    "# file5='ihm_results_lstm_channelwise_dep_16.json'\n",
    "# file7='ihm_results_gru_tr.json'\n",
    "# file8='ihm_results_gru_channelwise_tr.json'\n",
    "# file9='ihm_results_gru_channelwise.json'\n",
    "\n",
    "\n",
    "# summary_lstm = pd.read_json(file) \n",
    "# summary_lr = pd.read_json(file2)\n",
    "# summary_lr24 = pd.read_json(file3)\n",
    "\n",
    "# summary_lstm_tr = pd.read_json(file4)\n",
    "# summary_lstm_cw = pd.read_json(file5)\n",
    "# summary_gru_tr = pd.read_json(file7)\n",
    "\n",
    "summary_gru = pd.read_json(file6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "from matplotlib.cbook import _reshape_2D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def my_boxplot_stats(X, whis=1.5, bootstrap=None, labels=None,\n",
    "                  autorange=False, percents=[25, 75]):\n",
    "\n",
    "    def _bootstrap_median(data, N=5000):\n",
    "        # determine 95% confidence intervals of the median\n",
    "        M = len(data)\n",
    "        percentiles = [2.5, 97.5]\n",
    "\n",
    "        bs_index = np.random.randint(M, size=(N, M))\n",
    "        bsData = data[bs_index]\n",
    "        estimate = np.median(bsData, axis=1, overwrite_input=True)\n",
    "\n",
    "        CI = np.percentile(estimate, percentiles)\n",
    "        return CI\n",
    "\n",
    "    def _compute_conf_interval(data, med, iqr, bootstrap):\n",
    "        if bootstrap is not None:\n",
    "            # Do a bootstrap estimate of notch locations.\n",
    "            # get conf. intervals around median\n",
    "            CI = _bootstrap_median(data, N=bootstrap)\n",
    "            notch_min = CI[0]\n",
    "            notch_max = CI[1]\n",
    "        else:\n",
    "\n",
    "            N = len(data)\n",
    "            notch_min = med - 1.57 * iqr / np.sqrt(N)\n",
    "            notch_max = med + 1.57 * iqr / np.sqrt(N)\n",
    "\n",
    "        return notch_min, notch_max\n",
    "\n",
    "    # output is a list of dicts\n",
    "    bxpstats = []\n",
    "\n",
    "    # convert X to a list of lists\n",
    "    X = _reshape_2D(X, \"X\")\n",
    "\n",
    "    ncols = len(X)\n",
    "    if labels is None:\n",
    "        labels = itertools.repeat(None)\n",
    "    #elif len(labels) != ncols:\n",
    "    #    raise ValueError(\"Dimensions of labels and X must be compatible\")\n",
    "\n",
    "    input_whis = whis\n",
    "    #for ii, (x, label) in enumerate(zip(X, labels)):\n",
    "    \n",
    "    # empty dict\n",
    "    stats = {}\n",
    "    if labels is not None:\n",
    "        stats['label'] = labels\n",
    "\n",
    "    # restore whis to the input values in case it got changed in the loop\n",
    "    whis = input_whis\n",
    "\n",
    "    # note tricksyness, append up here and then mutate below\n",
    "    bxpstats.append(stats)\n",
    "\n",
    "    # if empty, bail\n",
    "    #if len(x) == 0:\n",
    "    stats['fliers'] = np.array([])\n",
    "    stats['mean'] = np.nan\n",
    "    stats['med'] = np.nan\n",
    "    stats['q1'] = np.nan\n",
    "    stats['q3'] = np.nan\n",
    "    stats['cilo'] = np.nan\n",
    "    stats['cihi'] = np.nan\n",
    "    stats['whislo'] = np.nan\n",
    "    stats['whishi'] = np.nan\n",
    "    stats['med'] = np.nan\n",
    "\n",
    "    x = np.asarray(X)[0]\n",
    "    stats['mean'] = np.mean(x)\n",
    "\n",
    "    # median\n",
    "    med = np.percentile(x, 50)\n",
    "    q1, q3 = np.percentile(x, (percents[0], percents[1]))\n",
    "\n",
    "    stats['iqr'] = q3 - q1\n",
    "    if stats['iqr'] == 0 and autorange:\n",
    "        whis = 'range'\n",
    "    stats['cilo'], stats['cihi'] = _compute_conf_interval(\n",
    "        x, med, stats['iqr'], bootstrap\n",
    "    )\n",
    "\n",
    "    if np.isscalar(whis):\n",
    "        if np.isreal(whis):\n",
    "            loval = q1 - whis * stats['iqr']\n",
    "            hival = q3 + whis * stats['iqr']\n",
    "        elif whis in ['range', 'limit', 'limits', 'min/max']:\n",
    "            loval = np.min(x)\n",
    "            hival = np.max(x)\n",
    "        else:\n",
    "            raise ValueError('whis must be a float, valid string, or list '\n",
    "                             'of percentiles')\n",
    "    else:\n",
    "        loval = np.percentile(x, whis[0])\n",
    "        hival = np.percentile(x, whis[1])\n",
    "\n",
    "    wiskhi = np.compress(x <= hival, x)\n",
    "    if len(wiskhi) == 0 or np.max(wiskhi) < q3:\n",
    "        stats['whishi'] = q3\n",
    "    else:\n",
    "        stats['whishi'] = np.max(wiskhi)\n",
    "\n",
    "    wisklo = np.compress(x >= loval, x)\n",
    "    if len(wisklo) == 0 or np.min(wisklo) > q1:\n",
    "        stats['whislo'] = q1\n",
    "    else:\n",
    "        stats['whislo'] = np.min(wisklo)\n",
    "\n",
    "    stats['fliers'] = np.hstack([\n",
    "        np.compress(x < stats['whislo'], x),\n",
    "        np.compress(x > stats['whishi'], x)\n",
    "    ])\n",
    "\n",
    "    stats['q1'], stats['med'], stats['q3'] = q1, med, q3\n",
    "\n",
    "    return bxpstats\n",
    "\n",
    "stats = {}\n",
    "\n",
    "# Compute the boxplot stats with our desired percentiles\n",
    "stats['G'] = my_boxplot_stats(summary_gru.loc[\"runs\"][1], labels='gru', percents=[2.5, 97.5])[0]\n",
    "# stats['A'] = my_boxplot_stats(summary_lr.loc[\"runs\"][1], labels='lr', percents=[2.5, 97.5])[0]\n",
    "# stats['B'] = my_boxplot_stats(summary_lr24.loc[\"runs\"][1], labels='lr24', percents=[2.5, 97.5])[0]\n",
    "# stats['C'] = my_boxplot_stats(summary_lstm.loc[\"runs\"][1], labels='lstm', percents=[2.5, 97.5])[0]\n",
    "# stats['D'] = my_boxplot_stats(summary_lstm_tr.loc[\"runs\"][1], labels='lstm_tr', percents=[2.5, 97.5])[0]\n",
    "# stats['E'] = my_boxplot_stats(summary_lstm_cw.loc[\"runs\"][1], labels='lstm_cw', percents=[2.5, 97.5])[0]\n",
    "# stats['H'] = my_boxplot_stats(summary_gru_tr.loc[\"runs\"][1], labels='gru_tr', percents=[2.5, 97.5])[0]\n",
    "# stats['I'] = my_boxplot_stats(summary_gru_cw[\"runs\"][1], labels='gru_cw', percents=[2.5, 97.5])[0]\n",
    "# stats['J'] = my_boxplot_stats(summary_gru_cw_tr[\"runs\"][1], labels='gru_cw_tr', percents=[2.5, 97.5])[0]\n",
    "# stats['F'] = my_boxplot_stats(summary_lstm_cw_tr[\"runs\"][1], labels='lstm_cw_tr', percents=[2.5, 97.5])[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# Plot boxplots from computed statistics\n",
    "bp = ax.bxp([stats['G']], positions=range(1), vert=False)\n",
    "#bp = ax.bxp([stats['A'], stats['B'], stats['C'], stats['D'], stats['E'], stats['F'],stats['G'],stats['H'],stats['I'],stats['J']], positions=range(10), vert=False)\n",
    "\n",
    "# Colour the lines in the boxplot blue\n",
    "for element in bp.keys():\n",
    "    plt.setp(bp[element], color='C0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. visualizing calibration (predicted vs observed mortality)\n",
    "'''\n",
    "try:\n",
    "    # lr \n",
    "    d=pd.read_csv(\"models/logistic/predictions/all.all.l2.C0.001_48.csv\")\n",
    "\n",
    "    #channel wise lstm\n",
    "    d2=pd.read_csv(\"models/test_predictions/k_channel_wise_lstms.n16.szc4.0.d0.3.dep2.bs8.ts1.0.epoch10.test0.2853237935876639.state.csv\")\n",
    "\n",
    "    # lstm with tr\n",
    "    d3=pd.read_csv(\"models/test_predictions/k_lstm.n16.d0.3.dep2.bs8.ts1.0.trc0.5.epoch10.test0.2944733425188627.state.csv\")\n",
    "\n",
    "    # gru with tr \n",
    "    d5=pd.read_csv(\"models/test_predictions/k_gru.n16.d0.3.dep2.bs8.ts1.0.trc0.5.epoch10.test0.28975883245579137.state.csv\")\n",
    "\n",
    "    # lstm\n",
    "    d6=pd.read_csv(\"test_predictions/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch10.test0.294850016698417.state.csv\")\n",
    "\n",
    "except:\n",
    "    # gru \n",
    "    pass\n",
    "d4=pd.read_csv(\"test_predictions/k_gru.n16.d0.3.dep2.bs8.ts1.0.epoch10.test0.2858196917729375.state.csv\")\n",
    "\n",
    "try: \n",
    "    d=d.sort_values('prediction')\n",
    "    d2=d2.sort_values('prediction')\n",
    "    d3=d3.sort_values('prediction')\n",
    "    d5=d5.sort_values('prediction')\n",
    "    d6=d6.sort_values('prediction')\n",
    "except:\n",
    "    pass\n",
    "d4=d4.sort_values('prediction')\n",
    "    \n",
    "import numpy as np\n",
    "bins = [x for x in np.linspace(0,1,11)]\n",
    "\n",
    "try:\n",
    "\n",
    "    d['binned'] = pd.cut(d['prediction'], bins)\n",
    "    d2['binned'] = pd.cut(d2['prediction'], bins)\n",
    "    d3['binned'] = pd.cut(d3['prediction'], bins)\n",
    "    d5['binned'] = pd.cut(d5['prediction'], bins)\n",
    "    d6['binned'] = pd.cut(d6['prediction'], bins)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "d4['binned'] = pd.cut(d4['prediction'], bins)\n",
    "\n",
    "try:\n",
    "    g =(d.groupby('binned')\n",
    "          .agg({'y_true':['mean'],'prediction':['mean'] }))\n",
    "\n",
    "    g2 =(d2.groupby('binned')\n",
    "          .agg({'y_true':['mean'],'prediction':['mean'] }))\n",
    "\n",
    "    g3 =(d3.groupby('binned')\n",
    "          .agg({'y_true':['mean'],'prediction':['mean'] }))\n",
    "\n",
    "    g5 =(d5.groupby('binned')\n",
    "          .agg({'y_true':['mean'],'prediction':['mean'] }))\n",
    "\n",
    "    g6 =(d6.groupby('binned')\n",
    "          .agg({'y_true':['mean'],'prediction':['mean'] }))\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "g4 =(d4.groupby('binned')\n",
    "      .agg({'y_true':['mean'],'prediction':['mean'] }))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "try:\n",
    "    ax.scatter(g['prediction'], g['y_true'], c=\".3\", label=\"logistic\")\n",
    "    ax.scatter(g2['prediction'], g2['y_true'], c=\"red\", label=\"channel-wise lstm\")\n",
    "\n",
    "    ax.scatter(g3['prediction'], g3['y_true'], c=\"orange\", label=\"lstm with tr\")\n",
    "\n",
    "    ax.scatter(g5['prediction'], g5['y_true'], c=\"purple\", label=\"gru with tr\")\n",
    "    ax.scatter(g6['prediction'], g6['y_true'], c=\"blue\", label=\"lstm\")\n",
    "except:\n",
    "    pass\n",
    "ax.scatter(g4['prediction'], g4['y_true'], c=\"cyan\", label=\"gru\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\".3\")\n",
    "ax.set_xlabel('predicted probability')     \n",
    "ax.set_ylabel('observed probability')     \n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. ROC curves\n",
    "'''\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "try:\n",
    "    #lr\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr, tpr, _ = roc_curve(d.iloc[:,2], d.iloc[:,1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    #cw lstm\n",
    "    roc_auc2 = dict()\n",
    "    fpr2, tpr2, _ = roc_curve(d2.iloc[:,2], d2.iloc[:,1])\n",
    "    roc_auc2 = auc(fpr2, tpr2)\n",
    "\n",
    "    #lstm tr\n",
    "    roc_auc3 = dict()\n",
    "    fpr3, tpr3, _ = roc_curve(d3.iloc[:,2], d3.iloc[:,1])\n",
    "    roc_auc3 = auc(fpr3, tpr3)\n",
    "\n",
    "    #gru tr\n",
    "\n",
    "    roc_auc5 = dict()\n",
    "    fpr5, tpr5, _ = roc_curve(d5.iloc[:,2], d5.iloc[:,1])\n",
    "    roc_auc5 = auc(fpr5, tpr5)\n",
    "\n",
    "    #lstm\n",
    "\n",
    "    roc_auc6 = dict()\n",
    "    fpr6, tpr6, _ = roc_curve(d6.iloc[:,2], d6.iloc[:,1])\n",
    "    roc_auc6 = auc(fpr6, tpr6)\n",
    "except:\n",
    "    pass\n",
    "#gru\n",
    "roc_auc4 = dict()\n",
    "fpr4, tpr4, _ = roc_curve(d4.iloc[:,2], d4.iloc[:,1])\n",
    "roc_auc4 = auc(fpr4, tpr4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "try:\n",
    "    ax.plot(fpr, tpr, color='black',\n",
    "             lw=2, label='ROC curve (area = %0.3f), LR' % roc_auc)\n",
    "    ax.plot(fpr2, tpr2, color='red',\n",
    "             lw=2, label='ROC curve (area = %0.3f), channel wise lstm' % roc_auc2)\n",
    "    ax.plot(fpr3, tpr3, color='green',\n",
    "             lw=2, label='ROC curve (area = %0.3f), lstm tr' % roc_auc3)\n",
    "    ax.plot(fpr5, tpr5, color='purple',\n",
    "             lw=2, label='ROC curve (area = %0.3f), gru tr' % roc_auc5)\n",
    "    ax.plot(fpr6, tpr6, color='cyan',\n",
    "             lw=2, label='ROC curve (area = %0.3f), lstm' % roc_auc6)\n",
    "except:\n",
    "    pass\n",
    "ax.plot(fpr4, tpr4, color='orange',\n",
    "         lw=2, label='ROC curve (area = %0.3f), gru' % roc_auc4)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], ls=\"--\", c=\".3\")\n",
    "\n",
    "ax.set_xlabel('fpr')     \n",
    "ax.set_ylabel('tpr')     \n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. PR curves\n",
    "'''\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def my_fun(x):\n",
    "    if x['prediction']>0.5 :\n",
    "        x['yhat']=1\n",
    "    else:\n",
    "        x['yhat']=0\n",
    "    return x  \n",
    " \n",
    "try:\n",
    "    d2=d2.apply(lambda x: my_fun(x), axis=1)\n",
    "    d3=d3.apply(lambda x: my_fun(x), axis=1)\n",
    "    d5=d5.apply(lambda x: my_fun(x), axis=1)\n",
    "    d6=d6.apply(lambda x: my_fun(x), axis=1)\n",
    "    d2=d2.apply(lambda x: my_fun(x), axis=1)\n",
    "    d=d.apply(lambda x: my_fun(x), axis=1)\n",
    "except:\n",
    "    pass\n",
    "d4=d4.apply(lambda x: my_fun(x), axis=1)\n",
    "\n",
    "try:\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(d.iloc[:,2], d.iloc[:,1])\n",
    "    lr_f1, lr_auc = f1_score(d['yhat'], d['y_true']), auc(lr_recall, lr_precision)\n",
    "\n",
    "    lr_precision2, lr_recall2, _ = precision_recall_curve(d2.iloc[:,2], d2.iloc[:,1])\n",
    "    lr_f12, lr_auc2 = f1_score(d2['yhat'], d2['y_true']), auc(lr_recall2, lr_precision2)\n",
    "\n",
    "    lr_precision3, lr_recall3, _ = precision_recall_curve(d3.iloc[:,2], d3.iloc[:,1])\n",
    "    lr_f13, lr_auc3 = f1_score(d3['yhat'], d3['y_true']), auc(lr_recall3, lr_precision3)\n",
    "\n",
    "    lr_precision5, lr_recall5, _ = precision_recall_curve(d5.iloc[:,2], d5.iloc[:,1])\n",
    "    lr_f15, lr_auc5 = f1_score(d5['yhat'], d5['y_true']), auc(lr_recall5, lr_precision5)\n",
    "\n",
    "    lr_precision6, lr_recall6, _ = precision_recall_curve(d6.iloc[:,2], d6.iloc[:,1])\n",
    "    lr_f16, lr_auc6 = f1_score(d6['yhat'], d6['y_true']), auc(lr_recall6, lr_precision6)\n",
    "except:\n",
    "    pass\n",
    "lr_precision4, lr_recall4, _ = precision_recall_curve(d4.iloc[:,2], d4.iloc[:,1])\n",
    "lr_f14, lr_auc4 = f1_score(d4['yhat'], d4['y_true']), auc(lr_recall4, lr_precision4)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "try:\n",
    "    ax.plot(lr_recall, lr_precision, color='black', lw=2, label='AUC PR (area = %0.3f), LR' % lr_auc)\n",
    "    ax.plot(lr_recall2, lr_precision2, color='red', lw=2, label='AUC PR (area = %0.3f), channel wise lstm' % lr_auc2)\n",
    "    ax.plot(lr_recall3, lr_precision3, color='green', lw=2, label='AUC PR (area = %0.3f), lstm tr' % lr_auc3)\n",
    "    ax.plot(lr_recall5, lr_precision5, color='purple', lw=2, label='AUC PR (area = %0.3f), gru tr' % lr_auc5)\n",
    "    ax.plot(lr_recall6, lr_precision6, color='cyan', lw=2, label='AUC PR (area = %0.3f), lstm' % lr_auc6)\n",
    "except:\n",
    "    pass\n",
    "ax.plot(lr_recall4, lr_precision4, color='orange', lw=2, label='AUC PR (area = %0.3f), gru' % lr_auc4)\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "\n",
    "ax.plot([1, 1], [0, 0], ls=\"--\", c=\".3\")\n",
    "\n",
    "# show the legend\n",
    "ax.legend()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
